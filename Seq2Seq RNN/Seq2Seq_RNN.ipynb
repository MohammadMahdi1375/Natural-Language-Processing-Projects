{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "###### spaCy has model for each language (\"de_core_news_sm\" for German and \"en_core_web_sm\" for English) which need to be loaded so we can access the tokenizer of each model\n",
    "spacy_de = spacy.load('de_core_news_sm')\n",
    "spacy_en = spacy.load('en_core_web_sm')\n",
    "import torch\n",
    "import random\n",
    "import evaluate\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "from datasets import load_metric \n",
    "from torchtext.datasets import Multi30k\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "BATCH_SIZE = 32\n",
    "random.seed(SEED)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#DEVICE ='cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1) Text Preprocessing and Bucketing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 26100\n",
      "Number of validating examples: 1450\n",
      "Number of testing examples: 1450\n"
     ]
    }
   ],
   "source": [
    "EN_Field = torchtext.data.Field(tokenize=lambda text: [token.text for token in spacy_en(text)], eos_token=\"<eos>\", init_token=\"<bos>\", lower=True, batch_first=False, include_lengths=True)\n",
    "DE_Field = torchtext.data.Field(tokenize=lambda text: [token.text for token in spacy_de(text)], eos_token=\"<eos>\", init_token=\"<bos>\", lower=True, batch_first=False, include_lengths=True)\n",
    "\n",
    "fields = [(\"de_text\", DE_Field), (\"en_text\", EN_Field)]\n",
    "\n",
    "train_en_data = pd.read_csv(\"./multi30k-dataset/data/task1/raw/train.en\", delimiter='\\t', header=None)\n",
    "train_de_data = pd.read_csv(\"./multi30k-dataset/data/task1/raw/train.de\", delimiter='\\t', header=None)\n",
    "\n",
    "df = pd.concat([train_de_data, train_en_data], axis=1)\n",
    "df.to_csv(\"data_de_en.csv\", index=False)\n",
    "TabularData = torchtext.data.TabularDataset(path=\"data_de_en.csv\",\n",
    "                                            format=\"CSV\",\n",
    "                                            fields=fields,\n",
    "                                            skip_header=True)\n",
    "train_data, valid_data, test_data = TabularData.split(split_ratio=[0.9, 0.05, 0.05], random_state=random.seed(SEED))\n",
    "train_Iterator = torchtext.data.BucketIterator(dataset=train_data,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               device=DEVICE,\n",
    "                                               sort_key=lambda x: len(x.en_text),\n",
    "                                               sort_within_batch=True)\n",
    "test_Iterator = torchtext.data.BucketIterator(dataset=test_data,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              device=DEVICE,\n",
    "                                              sort_key=lambda x: len(x.en_text),\n",
    "                                              sort_within_batch=True)\n",
    "valid_Iterator = torchtext.data.BucketIterator(dataset=valid_data,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              device=DEVICE,\n",
    "                                              sort_key=lambda x: len(x.en_text),\n",
    "                                              sort_within_batch=True)\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validating examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2) Creating Vocabulary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "Size of English vocabulary:  5641\n",
      "Size of Dutch vocabulary:  7344\n"
     ]
    }
   ],
   "source": [
    "EN_Field.build_vocab(train_data, min_freq=2)\n",
    "DE_Field.build_vocab(train_data, min_freq=2)\n",
    "print(EN_Field.vocab[\"young\"])\n",
    "print(\"Size of English vocabulary: \", len(EN_Field.vocab))\n",
    "print(\"Size of Dutch vocabulary: \", len(DE_Field.vocab))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3) Encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, bidirectional, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=input_dim, embedding_dim=emb_dim)\n",
    "        self.lstm = torch.nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=n_layers, batch_first=False, bidirectional=bidirectional, dropout=dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        ##### src shape: (seq_length, batch_size)\n",
    "        #print(f\"src_shape: {src.shape}\")\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        ##### embedding shape: (Seq_length, batch_size, embedding_size)\n",
    "        #print(f\"embedding_shape: {embedded.shape}\")\n",
    "        out, (h_n, c_n) = self.lstm(embedded)\n",
    "        \n",
    "        ##### The first layer will receive a hidden and cell state from the previous time-step (It should be passed to the decoder as the h_0, and c_0)\n",
    "        return h_n, c_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4) Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, out_dim, emb_dim, hid_dim, n_layers, bidirectional, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(num_embeddings=out_dim, embedding_dim=emb_dim)\n",
    "        self.lstm = torch.nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=n_layers, batch_first=False, bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = torch.nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        ###### shape of input: (batch_size) but we want to be (1, batch_size) so we use unsqueeze\n",
    "        input = input.unsqueeze(0)\n",
    "        ###### shape of input: (1, batch_size)\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        ###### shape of embedded: (1, batch_size, embedding_size)\n",
    "        \n",
    "        out, (h_n, c_n) = self.lstm(embedded, (hidden, cell))\n",
    "        ###### shape of out: (1, batch_size, hidden_size)\n",
    "        \n",
    "        prediction = self.fc(out.squeeze(0))\n",
    "        ###### shape of Predictions: (1, batch_size, length_of_EN_vocabulary)\n",
    "        \n",
    "        prediction = prediction.squeeze()\n",
    "        \n",
    "        return prediction, h_n, c_n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5) Seq2Seq**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(torch.nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing=True):\n",
    "        ##### trg shape: (trg_len, Batch_size)\n",
    "        trg_len = trg.shape[0]\n",
    "        N = trg.shape[1]\n",
    "        Y_hat = torch.zeros((trg_len, N, self.decoder.out_dim))\n",
    "\n",
    "        s_0, c_0 = self.encoder(src)\n",
    "\n",
    "        ## Selecting the first word in each target sentence in the batch to start decoding. It is \"<bos>\" token.\n",
    "        input = trg[0]\n",
    "\n",
    "        for i in range(1, trg_len):\n",
    "            y_hat, s_0, c_0 = self.decoder(input, s_0, c_0)\n",
    "\n",
    "            ##### y_hat shape: (Btach_size, length_of_EN_vocabulary)\n",
    "            Y_hat[i] = y_hat\n",
    "\n",
    "            \n",
    "            if(teacher_forcing):\n",
    "                input = trg[i]\n",
    "            else:\n",
    "                ##### argmax(1) because we want to apply the argmax over the second dim of y_hat ----> y_hat.argmax(1): (Batch_size, 1)\n",
    "                input = y_hat.argmax(1).squeeze()\n",
    "        return Y_hat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6) Parameter initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (embedding): Embedding(7344, 300)\n",
      "    (lstm): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(5641, 300)\n",
      "    (lstm): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
      "    (fc): Linear(in_features=1024, out_features=5641, bias=True)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 37333717\n",
      "unk_token: 0\n",
      "pad_token: 1\n",
      "eos_token: 3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(DE_Field.vocab)\n",
    "OUTPUT_DIM = len(EN_Field.vocab)\n",
    "ENC_EMB_DIM = 300\n",
    "DEC_EMB_DIM = 300\n",
    "HID_DIM = 1024\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "BIDIRECTIONAL = False\n",
    "\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, BIDIRECTIONAL, ENC_DROPOUT)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, BIDIRECTIONAL, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "print(f\"Total number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "\n",
    "Optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "# by passing the index of the <pad> token as the ignore_index argument we ignore the loss whenever the target token is a padding token.\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index = EN_Field.vocab.stoi[\"<pad>\"])\n",
    "\n",
    "\n",
    "print(f\"unk_token: {EN_Field.vocab.stoi[EN_Field.unk_token]}\")\n",
    "print(f\"pad_token: {EN_Field.vocab.stoi[EN_Field.pad_token]}\")\n",
    "print(f\"eos_token: {EN_Field.vocab.stoi[EN_Field.eos_token]}\")\n",
    "print(EN_Field.vocab.stoi[\".\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7) Train function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        src = batch.de_text[0]\n",
    "        trg = batch.en_text[0]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output = output[1:].view(-1, output.shape[2])\n",
    "        trg = trg[1:].view(-1)\n",
    "        output = output.to(DEVICE)\n",
    "        trg = trg.to(DEVICE)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **8) Evaluation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            \n",
    "\n",
    "            src = batch.de_text[0]\n",
    "            trg = batch.en_text[0]\n",
    "\n",
    "            output = model(src, trg, False) #turn off teacher forcing\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[2])\n",
    "            trg = trg[1:].view(-1)\n",
    "            output = output.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "\tTrain Loss: 4.597 | Train PPL:  99.209\n",
      "\tVal. Loss: 5.762 |  Val. PPL: 318.070\n",
      "Epoch: 2\n",
      "\tTrain Loss: 3.852 | Train PPL:  47.109\n",
      "\tVal. Loss: 5.966 |  Val. PPL: 389.993\n",
      "Epoch: 3\n",
      "\tTrain Loss: 3.563 | Train PPL:  35.276\n",
      "\tVal. Loss: 5.886 |  Val. PPL: 360.127\n",
      "Epoch: 4\n",
      "\tTrain Loss: 3.329 | Train PPL:  27.912\n",
      "\tVal. Loss: 5.951 |  Val. PPL: 384.308\n",
      "Epoch: 5\n",
      "\tTrain Loss: 3.142 | Train PPL:  23.158\n",
      "\tVal. Loss: 5.786 |  Val. PPL: 325.851\n",
      "Epoch: 6\n",
      "\tTrain Loss: 2.994 | Train PPL:  19.966\n",
      "\tVal. Loss: 5.720 |  Val. PPL: 304.792\n",
      "Epoch: 7\n",
      "\tTrain Loss: 2.868 | Train PPL:  17.598\n",
      "\tVal. Loss: 5.671 |  Val. PPL: 290.256\n",
      "Epoch: 8\n",
      "\tTrain Loss: 2.755 | Train PPL:  15.715\n",
      "\tVal. Loss: 5.648 |  Val. PPL: 283.636\n",
      "Epoch: 9\n",
      "\tTrain Loss: 2.653 | Train PPL:  14.195\n",
      "\tVal. Loss: 5.653 |  Val. PPL: 285.233\n",
      "Epoch: 10\n",
      "\tTrain Loss: 2.557 | Train PPL:  12.900\n",
      "\tVal. Loss: 5.608 |  Val. PPL: 272.486\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss = train(model, train_Iterator, Optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_Iterator, criterion)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\tVal. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9) Computing Metrics (Bleu Score, Rouge, WER)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46/46 [27:48<00:00, 36.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Average Testing Bleu Score is: 0.0\n",
      "The Average Testing Rouge-1 Score is: 0.1391844802309793\n",
      "The Average Testing Rouge-2 Score is: 0.006443801035686695\n",
      "The Average Testing Rouge-L Score is: 0.10549167452135848\n",
      "The Average Testing Rouge-Lsum Score is: 0.10549167452135848\n",
      "Average Word Error Rate: 1.0090863994647892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to translate a sentence using argmax\n",
    "def translate_sentence(model, sentence, src_field, tgt_field, device, max_len=50):\n",
    "    model.eval()\n",
    "    tokens = src_field.tokenize(sentence)\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
    "    src_len = torch.LongTensor([len(src_indexes)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h_0_decoder, c_0_decoder = model.encoder(src_tensor)\n",
    "\n",
    "    trg_indexes = [tgt_field.vocab.stoi[tgt_field.init_token]]\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output, h_0_decoder, c_0_decoder = model.decoder(trg_tensor, h_0_decoder, c_0_decoder)\n",
    "\n",
    "        pred_token = output.argmax(0).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == tgt_field.vocab.stoi[tgt_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "\n",
    "    trg_tokens = [tgt_field.vocab.itos[i] for i in trg_indexes]\n",
    "    return trg_tokens[1:-1], trg_indexes[1:-1]\n",
    "\n",
    "# Translate each test data point using argmax and print the English sentence, the ground truth Dutch translation, and the model's generated Dutch translation\n",
    "predicted_output = []\n",
    "ground_truth_output = []\n",
    "bleu = load_metric(\"bleu\") \n",
    "rouge = evaluate.load('rouge')\n",
    "Bleu_total = 0\n",
    "rouge1_total = 0\n",
    "rouge2_total = 0\n",
    "rougeL_total = 0\n",
    "rougeLsum_total = 0\n",
    "WER_total = 0\n",
    "n = 0\n",
    "for batch in tqdm(valid_Iterator):\n",
    "    src = batch.en_text[0]\n",
    "    trg = batch.de_text[0]\n",
    "\n",
    "\n",
    "    for idx in range(src.shape[1]):\n",
    "        src_sent = ' '.join([EN_Field.vocab.itos[i] for i in src[1:src.shape[0]-1, idx]])\n",
    "        trg_sent = ' '.join([DE_Field.vocab.itos[i] for i in trg[1:, idx]])\n",
    "        \n",
    "        trg_sent = trg_sent.split(\" \")\n",
    "\n",
    "        final_trg = [] \n",
    "        for w in trg_sent:\n",
    "            if w != '<pad>' and w != '<eos>':\n",
    "                final_trg.append(w)\n",
    "\n",
    "        final_trg = \" \".join(w for w in final_trg)\n",
    "\n",
    "        translated_sent, _ = translate_sentence(model, src_sent, EN_Field, DE_Field, DEVICE)\n",
    "\n",
    "        predicted_output = translated_sent\n",
    "        ground_truth_output = final_trg.split()\n",
    "\n",
    "        ## Computing the Rouge\n",
    "        results = rouge.compute(predictions=[' '.join(predicted_output)], references=[final_trg])\n",
    "        rouge1_total += results['rouge1']\n",
    "        rouge2_total += results['rouge2']\n",
    "        rougeL_total += results['rougeL']\n",
    "        rougeLsum_total += results['rougeLsum']\n",
    "\n",
    "        ## Computing the Word Error Rate\n",
    "        WER_total += wer(final_trg, ' '.join(predicted_output))\n",
    "\n",
    "        ## Computing the BLEU score\n",
    "        predicted_output = [predicted_output]\n",
    "        ground_truth_output = [[ground_truth_output]]\n",
    "\n",
    "        Bleu_total += bleu.compute(predictions=predicted_output, references=ground_truth_output)['bleu']\n",
    "        n += 1\n",
    "\n",
    "\n",
    "print(f\"The Average Testing Bleu Score is: {Bleu_total / n}\")\n",
    "print(f\"The Average Testing Rouge-1 Score is: {rouge1_total / n}\")\n",
    "print(f\"The Average Testing Rouge-2 Score is: {rouge2_total / n}\")\n",
    "print(f\"The Average Testing Rouge-L Score is: {rougeL_total / n}\")\n",
    "print(f\"The Average Testing Rouge-Lsum Score is: {rougeLsum_total / n}\")\n",
    "print(f\"Average Word Error Rate: {WER_total / n}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pyth310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
